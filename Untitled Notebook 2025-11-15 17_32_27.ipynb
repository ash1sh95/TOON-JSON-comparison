{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6501955e-ee85-48b7-ab5c-b892c5c8bae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Token Consumption Comparison: JSON vs TOON Format for LLMs\n",
    "\n",
    "This notebook demonstrates a practical comparison of token consumption between the standard JSON format and a custom TOON format, using a sample data structure. The goal is to help users understand how different serialization formats impact token usage when interacting with Large Language Models (LLMs).\n",
    "\n",
    "**Key Steps:**\n",
    "* Generate representative sample data\n",
    "* Serialize the data to JSON and TOON formats\n",
    "* Count tokens in each format using whitespace splitting (a simple proxy for LLM tokenization)\n",
    "* Summarize the results and implications for LLM usage\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e890dfbf-09a2-401e-a120-76e587c30dde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'user': {'id': 123,\n",
       "  'name': 'Alice',\n",
       "  'roles': ['admin', 'user'],\n",
       "  'active': True},\n",
       " 'metrics': {'score': 98.5, 'rank': 1, 'tags': ['top', 'verified']}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Generate sample data\n",
    "# This dictionary simulates a typical payload that might be sent to an LLM for processing.\n",
    "# It includes nested fields and lists to represent realistic complexity.\n",
    "sample_data = {\n",
    "    \"user\": {\n",
    "        \"id\": 123,\n",
    "        \"name\": \"Alice\",\n",
    "        \"roles\": [\"admin\", \"user\"],\n",
    "        \"active\": True\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"score\": 98.5,\n",
    "        \"rank\": 1,\n",
    "        \"tags\": [\"top\", \"verified\"]\n",
    "    }\n",
    "}\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f549c7f-e5ae-4adc-9468-6735a7053a28",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Serialize sample data to JSON"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'{\"user\": {\"id\": 123, \"name\": \"Alice\", \"roles\": [\"admin\", \"user\"], \"active\": true}, \"metrics\": {\"score\": 98.5, \"rank\": 1, \"tags\": [\"top\", \"verified\"]}}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Serialize sample data to JSON format\n",
    "# JSON is a widely used serialization format for APIs and LLMs.\n",
    "# We use the standard json library to convert the dictionary to a JSON string.\n",
    "import json\n",
    "json_str = json.dumps(sample_data)\n",
    "json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87e95ff6-d79c-40b4-83d3-523fb315252b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Serialize sample data to TOOn format"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'user.id=123;\\nuser.name=Alice;\\nuser.roles=[admin, user];\\nuser.active=True;\\nmetrics.score=98.5;\\nmetrics.rank=1;\\nmetrics.tags=[top, verified];'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Serialize sample data to TOON format\n",
    "# TOON is a custom, flat key-value format for demonstration purposes.\n",
    "# It flattens nested dictionaries and lists into a compact string representation.\n",
    "def to_toon(data, parent_key=''):\n",
    "    items = []\n",
    "    for k, v in data.items():\n",
    "        key = f\"{parent_key}.{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.append(to_toon(v, key))\n",
    "        elif isinstance(v, list):\n",
    "            items.append(f\"{key}=[{', '.join(map(str, v))}];\")\n",
    "        else:\n",
    "            items.append(f\"{key}={v};\")\n",
    "    return '\\n'.join(items)\n",
    "\n",
    "toon_str = to_toon(sample_data)\n",
    "toon_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "685af21f-96c0-4b39-bd86-0cde250751e8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Count tokens in JSON and TOOn formats"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON token count: 18\nTOOn token count: 9\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Count tokens in both formats\n",
    "# Tokenization here uses whitespace splitting as a simple proxy for LLM tokenization.\n",
    "# For production use, consider using the tokenizer specific to your LLM (e.g., OpenAI tiktoken).\n",
    "def count_tokens(text):\n",
    "    return len(text.split())\n",
    "\n",
    "json_token_count = count_tokens(json_str)\n",
    "toon_token_count = count_tokens(toon_str)\n",
    "\n",
    "print(f\"JSON token count: {json_token_count}\")\n",
    "print(f\"TOON token count: {toon_token_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95678d40-5ef5-46c7-86cf-e05aec42511f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Results: Token Consumption Comparison\n",
    "\n",
    "* The sample data was serialized to both JSON and TOON formats.\n",
    "* Token count (using whitespace splitting):\n",
    "  * **JSON format:** 18 tokens\n",
    "  * **TOON format:** 9 tokens\n",
    "* The TOON format resulted in fewer tokens for this sample, likely due to its more compact, flat representation.\n",
    "\n",
    "### Implications for LLM Usage\n",
    "* Fewer tokens can reduce LLM costs and improve performance, especially for large payloads or frequent API calls.\n",
    "* The actual token count may vary depending on the LLM's tokenizer; this notebook uses whitespace splitting for simplicity.\n",
    "* Custom formats like TOON may be beneficial for specific use cases, but always validate with your target LLM's tokenizer.\n",
    "\n",
    "---\n",
    "**Feel free to adapt this notebook for your own data and LLM workflows.**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-11-15 17:32:27",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}